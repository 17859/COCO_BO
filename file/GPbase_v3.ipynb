{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c6b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "import torch\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from functools import wraps\n",
    "from contextlib import redirect_stdout\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import SumMarginalLogLikelihood\n",
    "from gpytorch.kernels import (\n",
    "    ScaleKernel,\n",
    "    MaternKernel,\n",
    "    RBFKernel,\n",
    ")\n",
    "\n",
    "\n",
    "# --- Logging 配置 ---\n",
    "logger = logging.getLogger(\"BO_Monitor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    ch = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Decorator\n",
    "# ============================================================\n",
    "\n",
    "def monitor(runtime=True, memory=True, condition=False):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            if not getattr(self, \"debug\", False):\n",
    "                return func(self, *args, **kwargs)\n",
    "\n",
    "            # 確保類別中有存儲紀錄的容器\n",
    "            if not hasattr(self, 'performance_history'):\n",
    "                self.performance_history = []\n",
    "\n",
    "            # 紀錄開始資訊\n",
    "            start_time = time.perf_counter()\n",
    "            process = psutil.Process(os.getpid())\n",
    "            \n",
    "            # 執行函數\n",
    "            result = func(self, *args, **kwargs)\n",
    "            \n",
    "            # 計算指標\n",
    "            end_time = time.perf_counter()\n",
    "            elapsed = end_time - start_time\n",
    "            cpu_mem = process.memory_info().rss / 1024**2\n",
    "            \n",
    "            entry = {\n",
    "                \"iteration\": getattr(self, \"current_iter\", \"N/A\"), # 追蹤當前疊代次數\n",
    "                \"function\": func.__name__,\n",
    "                \"runtime_sec\": round(elapsed, 4),\n",
    "                \"cpu_memory_mb\": round(cpu_mem, 2),\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                entry[\"gpu_alloc_mb\"] = round(torch.cuda.memory_allocated() / 1024**2, 2)\n",
    "\n",
    "            # 如果需要紀錄條件數 (僅針對 fit 後的模型)\n",
    "            if condition and getattr(self, \"model\", None) is not None:\n",
    "                cond_list = []\n",
    "                for i, m in enumerate(self.model.models):\n",
    "                    with torch.no_grad():\n",
    "                        K = m.covar_module(m.train_inputs[0]).evaluate()\n",
    "                        eigvals = torch.linalg.eigvalsh(K)\n",
    "                        cond = (eigvals.max() / eigvals.min()).item()\n",
    "                        cond_list.append(cond)\n",
    "                entry[\"condition_numbers\"] = cond_list\n",
    "\n",
    "            # 儲存到物件歷史紀錄\n",
    "            self.performance_history.append(entry)\n",
    "            \n",
    "            # 同時印出日誌供參考\n",
    "            logger.info(f\"Finished {func.__name__} - {entry}\")\n",
    "            \n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BaselineGPEmulator:\n",
    "    \"\"\"\n",
    "    Baseline Multi-Objective GP Emulator\n",
    "    =====================================\n",
    "\n",
    "    This class implements a multi-objective Gaussian Process (GP)\n",
    "    surrogate model using independent SingleTaskGP models.\n",
    "\n",
    "    Mathematical Form:\n",
    "\n",
    "        y_k(z) = m_k(z) + g_k(z)\n",
    "\n",
    "        m_k(z) : constant mean (default in SingleTaskGP)\n",
    "        g_k(z) ~ GP(0, K_{θ_k})\n",
    "\n",
    "    Each objective is modeled with an independent GP.\n",
    "\n",
    "    Example:\n",
    "        >>> import torch\n",
    "        >>> from baseline_gp_emulator import BaselineGPEmulator\n",
    "        >>>\n",
    "        >>> # Generate training data\n",
    "        >>> train_X = torch.rand(20, 3, dtype=torch.double)\n",
    "        >>> train_Y = torch.rand(20, 2, dtype=torch.double)\n",
    "        >>>\n",
    "        >>> # Create emulator\n",
    "        >>>\n",
    "        >>> # method1 : RBF is defult\n",
    "        >>> emulator = BaselineGPEmulator()  #defult = RBF\n",
    "        >>>\n",
    "        >>> # method2 : matern\n",
    "        >>> emulator = BaselineGPEmulator(\n",
    "        ...     kernel=\"matern\"\n",
    "        ... )\n",
    "        >>>\n",
    "        >>> # Fit model\n",
    "        >>> model = emulator.fit(train_X, train_Y)\n",
    "        >>>\n",
    "        >>> # Make predictions\n",
    "        >>> test_X = torch.rand(5, 3, dtype=torch.double)\n",
    "        >>> mean, var = emulator.predict(test_X)\n",
    "        >>>\n",
    "        >>> mean.shape\n",
    "        torch.Size([5, 2])\n",
    "        >>> var.shape\n",
    "        torch.Size([5, 2])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        dtype   = torch.double,\n",
    "        kernel    = \"rbf\",      # \"rbf\" or \"matern\"\n",
    "        use_ard   = False,       # Whether to use Automatic Relevance Determination\n",
    "        matern_nu = 2.5,         # Smoothness parameter for Matern kernel\n",
    "        debug=False,   # Debug switch\n",
    "        \n",
    "    \n",
    "    ):\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.model = None\n",
    "        self.mll = None\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.use_ard = use_ard\n",
    "        self.matern_nu = matern_nu\n",
    "        self.debug = debug\n",
    "        self.performance_history = []\n",
    "        self.current_iter = 0\n",
    "\n",
    "\n",
    "    def _build_kernel(self, input_dim):\n",
    "\n",
    "        \"\"\"\n",
    "        Construct covariance kernel based on configuration.\n",
    "\n",
    "        If ARD is enabled, each input dimension has its own\n",
    "        independent lengthscale parameter.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        ard_dims = input_dim if self.use_ard else None\n",
    "\n",
    "        if self.kernel == \"matern\":\n",
    "            base_kernel = MaternKernel(\n",
    "                nu=self.matern_nu,\n",
    "                ard_num_dims=ard_dims,\n",
    "            )\n",
    "        else:  # default: RBF\n",
    "            base_kernel = RBFKernel(\n",
    "                ard_num_dims=ard_dims,\n",
    "            )\n",
    "\n",
    "        # ScaleKernel allows the model to learn an output scale parameter\n",
    "        return ScaleKernel(base_kernel)\n",
    "\n",
    "\n",
    "    @monitor(runtime=True, memory=True, condition=True)\n",
    "    def fit(self, train_x: torch.Tensor, train_obj: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Fit the multi-objective GP surrogate model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_x : torch.Tensor\n",
    "            Training inputs of shape (N, d)\n",
    "\n",
    "        train_obj : torch.Tensor\n",
    "            Training objectives of shape (N, k)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ModelListGP\n",
    "            A ModelListGP containing independent SingleTaskGP models\n",
    "            for each objective.\n",
    "        \"\"\"\n",
    "\n",
    "        # If single objective (N,), convert to (N, 1)\n",
    "        if train_obj.ndim == 1:\n",
    "            train_obj = train_obj.unsqueeze(-1)\n",
    "\n",
    "        input_dim = train_x.shape[-1]\n",
    "        num_objectives = train_obj.shape[-1]\n",
    "\n",
    "        models = []\n",
    "        \n",
    "        # Build one independent GP per objective\n",
    "        for i in range(num_objectives):\n",
    "            covar_module = self._build_kernel(input_dim)\n",
    "\n",
    "            train_y = train_obj[..., i:i + 1]  # (N, 1)\n",
    "\n",
    "            gp = SingleTaskGP(\n",
    "                train_X=train_x,\n",
    "                train_Y=train_y,\n",
    "                outcome_transform=Standardize(m=1),\n",
    "                covar_module=covar_module,\n",
    "            )\n",
    "            models.append(gp)\n",
    "\n",
    "        # Combine independent GPs into ModelListGP\n",
    "        self.model = ModelListGP(*models)\n",
    "\n",
    "        # Define marginal log likelihood for multi-model case\n",
    "        self.mll = SumMarginalLogLikelihood(\n",
    "            self.model.likelihood, self.model\n",
    "        )\n",
    "        with open(os.devnull, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                fit_gpytorch_mll(self.mll)\n",
    "\n",
    "\n",
    "        # Maximize marginal log likelihood\n",
    "        fit_gpytorch_mll(self.mll)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def save_performance_to_json(self, folder_path, filename=\"performance_report.json\"):\n",
    "        \"\"\"\n",
    "        將監控紀錄儲存至指定資料夾路徑。\n",
    "        \"\"\"\n",
    "        # 1. 確保資料夾存在，若不存在則自動建立\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            logger.info(f\"Created directory: {folder_path}\")\n",
    "\n",
    "        # 2. 合併完整路徑\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # 3. 寫入 JSON\n",
    "        try:\n",
    "            with open(full_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.performance_history, f, indent=4, ensure_ascii=False)\n",
    "            logger.info(f\"Successfully saved performance metrics to: {full_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save JSON: {str(e)}\")\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, X ):\n",
    "        \"\"\"\n",
    "        Predict using the trained GP surrogate.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor or array-like\n",
    "            Input locations of shape (n, d)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mean : torch.Tensor\n",
    "            Posterior predictive mean of shape (n, k)\n",
    "\n",
    "        var : torch.Tensor\n",
    "            Posterior predictive variance of shape (n, k)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been fitted yet.\")\n",
    "        \n",
    "        X = torch.as_tensor(X, dtype=self.dtype, device=self.device)\n",
    "        posterior = self.model.posterior(X)\n",
    "        mean = posterior.mean    # (n, k)\n",
    "        var = posterior.variance # (n, k)\n",
    "\n",
    "        return mean, var\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9404f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import SumMarginalLogLikelihood\n",
    "from gpytorch.means import Mean\n",
    "from gpytorch.kernels import ScaleKernel, MaternKernel, RBFKernel\n",
    "\n",
    "import torch\n",
    "import itertools\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "from functools import wraps\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Optimized Mean Function: IDXSFastScheffeMean \n",
    "# ============================================================\n",
    "class IdxsFastScheffeMean(Mean):\n",
    "    \"\"\"\n",
    "    High-performance Scheffé polynomial mean function.\n",
    "\n",
    "    Mathematical form:\n",
    "\n",
    "        m(z) =\n",
    "            Σ β_i z_i\n",
    "          + Σ β_ij z_i z_j\n",
    "          + Σ β_ijk z_i z_j z_k\n",
    "          + Σ β_ijkl z_i z_j z_k z_l\n",
    "\n",
    "    depending on order.\n",
    "\n",
    "    Design goals:\n",
    "    - No torch.pow\n",
    "    - No mask matrix\n",
    "    - No large broadcast tensor\n",
    "    - No Python inner loops in forward\n",
    "    - Optimized for optimize_acqf gradient loops\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, order=2):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Number of mixture components (dimension d)\n",
    "\n",
    "        order : int\n",
    "            Polynomial order (1 ~ 4 supported)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.order = order\n",
    "\n",
    "        num_params = 0\n",
    "        \n",
    "        # --------------------------------------------------\n",
    "        # 1st-order terms (linear effects)\n",
    "        # --------------------------------------------------\n",
    "        # z1, z2, ..., zd\n",
    "        self.register_buffer(\"idx1\", torch.arange(input_dim))\n",
    "        num_params += input_dim\n",
    "\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 2nd-order interaction terms\n",
    "        # --------------------------------------------------\n",
    "        # zi * zj for i < j\n",
    "        if order >= 2:\n",
    "            idx2_i, idx2_j = torch.triu_indices(input_dim, input_dim, offset=1)\n",
    "            self.register_buffer(\"idx2_i\", idx2_i)\n",
    "            self.register_buffer(\"idx2_j\", idx2_j)\n",
    "            num_params += len(idx2_i)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 3rd-order interaction terms\n",
    "        # --------------------------------------------------\n",
    "        # zi * zj * zk\n",
    "        if order >= 3:\n",
    "            comb3 = torch.combinations(torch.arange(input_dim), r=3)\n",
    "            self.register_buffer(\"idx3\", comb3)\n",
    "            num_params += comb3.shape[0]\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 4th-order interaction terms\n",
    "        # --------------------------------------------------\n",
    "        # zi * zj * zk * zl\n",
    "\n",
    "        if order >= 4:\n",
    "            comb4 = torch.combinations(torch.arange(input_dim), r=4)\n",
    "            self.register_buffer(\"idx4\", comb4)\n",
    "            num_params += comb4.shape[0]\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Trainable coefficients β\n",
    "        # --------------------------------------------------\n",
    "        # Total parameters = Σ C(d, k)\n",
    "\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(num_params))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute Scheffé mean.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Tensor\n",
    "            Shape (..., n, d)\n",
    "            where d = input_dim\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mean : Tensor\n",
    "            Shape (..., n)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        features = []\n",
    "\n",
    "        # -------------------------\n",
    "        # 1st order\n",
    "        # -------------------------\n",
    "        features.append(X)\n",
    "\n",
    "        # -------------------------\n",
    "        # 2nd order\n",
    "        # -------------------------\n",
    "        if self.order >= 2:\n",
    "            F2 = X[..., self.idx2_i] * X[..., self.idx2_j]\n",
    "            features.append(F2)\n",
    "\n",
    "        # -------------------------\n",
    "        # 3rd order\n",
    "        # -------------------------\n",
    "        if self.order >= 3:\n",
    "            i, j, k = self.idx3.unbind(dim=1)\n",
    "            F3 = X[..., i] * X[..., j] * X[..., k]\n",
    "            features.append(F3)\n",
    "\n",
    "        # -------------------------\n",
    "        # 4th order\n",
    "        # -------------------------\n",
    "        if self.order >= 4:\n",
    "            i, j, k, l = self.idx4.unbind(dim=1)\n",
    "            F4 = X[..., i] * X[..., j] * X[..., k] * X[..., l]\n",
    "            features.append(F4)\n",
    "\n",
    "        # -------------------------\n",
    "        # Concatenate all polynomial terms\n",
    "        # -------------------------\n",
    "        F = torch.cat(features, dim=-1)\n",
    "\n",
    "        # Linear combination with β\n",
    "        return torch.matmul(F, self.beta)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Monitoring Utilities\n",
    "# ============================================================\n",
    "\n",
    "logger = logging.getLogger(\"BO_Monitor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    ch = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "\n",
    "\n",
    "def monitor(runtime=True, memory=True, condition=False):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            if not getattr(self, \"debug\", False):\n",
    "                return func(self, *args, **kwargs)\n",
    "            if not hasattr(self, 'performance_history'):\n",
    "                self.performance_history = []\n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            process = psutil.Process(os.getpid())\n",
    "            \n",
    "            result = func(self, *args, **kwargs)\n",
    "            \n",
    "            elapsed = time.perf_counter() - start_time\n",
    "            cpu_mem = process.memory_info().rss / 1024**2\n",
    "            \n",
    "            entry = {\n",
    "                \"iteration\": getattr(self, \"current_iter\", \"N/A\"),\n",
    "                \"function\": func.__name__,\n",
    "                \"runtime_sec\": round(elapsed, 4),\n",
    "                \"cpu_memory_mb\": round(cpu_mem, 2),\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            if torch.cuda.is_available():\n",
    "                entry[\"gpu_alloc_mb\"] = round(torch.cuda.memory_allocated() / 1024**2, 2)\n",
    "            \n",
    "            self.performance_history.append(entry)\n",
    "            logger.info(f\"Finished {func.__name__} - {entry}\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Scheffé Trend GP Emulator IDX ver.\n",
    "# ============================================================\n",
    "class IdxsScheffeTrendGPEmulator:\n",
    "    \"\"\"\n",
    "    Universal Kriging model:\n",
    "\n",
    "        f(x) = Scheffé polynomial trend + GP residual\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        dtype         = torch.double,\n",
    "        kernel        = 'rbf',\n",
    "        use_ard       = False,\n",
    "        matern_nu     = 2.5,\n",
    "        scheffe_order = 2,\n",
    "        debug         = False,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.kernel = kernel\n",
    "        self.use_ard = use_ard\n",
    "        self.matern_nu = matern_nu\n",
    "        self.scheffe_order = scheffe_order\n",
    "        self.debug = debug\n",
    "        self.performance_history = []\n",
    "        self.current_iter = 0\n",
    "        self.model = None\n",
    "\n",
    "    def _build_kernel(self, input_dim):\n",
    "        ard_dims = input_dim if self.use_ard else None\n",
    "        if self.kernel == \"matern\":\n",
    "            base_kernel = MaternKernel(nu=self.matern_nu, ard_num_dims=ard_dims)\n",
    "        else:\n",
    "            base_kernel = RBFKernel(ard_num_dims=ard_dims)\n",
    "        return ScaleKernel(base_kernel)\n",
    "\n",
    "    @monitor(runtime=True, memory=True, condition=True)\n",
    "    def fit(self, train_x: torch.Tensor, train_obj: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Fit multi-objective GP model.\n",
    "        \"\"\"\n",
    "        train_x = train_x.to(device=self.device, dtype=self.dtype)\n",
    "        train_obj = train_obj.to(device=self.device, dtype=self.dtype)\n",
    "\n",
    "        if train_obj.ndim == 1:\n",
    "            train_obj = train_obj.unsqueeze(-1)\n",
    "\n",
    "        input_dim = train_x.shape[-1]\n",
    "        num_objectives = train_obj.shape[-1]\n",
    "        models = []\n",
    "\n",
    "        for i in range(num_objectives):\n",
    "            covar_module = self._build_kernel(input_dim)\n",
    "\n",
    "            mean_module = IdxsFastScheffeMean(\n",
    "                input_dim=input_dim,\n",
    "                order=self.scheffe_order,\n",
    "            ).to(device=self.device, dtype=self.dtype) \n",
    "\n",
    "            train_y = train_obj[..., i:i + 1]\n",
    "\n",
    "            gp = SingleTaskGP(\n",
    "                train_X=train_x,\n",
    "                train_Y=train_y,\n",
    "                mean_module=mean_module,\n",
    "                outcome_transform=Standardize(m=1),\n",
    "                covar_module=covar_module,\n",
    "            )\n",
    "            models.append(gp)\n",
    "\n",
    "        self.model = ModelListGP(*models).to(device=self.device, dtype=self.dtype)\n",
    "        self.mll = SumMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "\n",
    "        with open(os.devnull, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                fit_gpytorch_mll(self.mll)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def save_performance_to_json(self, folder_path, filename=\"performance_report.json\"):\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            with open(full_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.performance_history, f, indent=4, ensure_ascii=False)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save JSON: {str(e)}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been fitted yet.\")\n",
    "        X = torch.as_tensor(X, dtype=self.dtype, device=self.device)\n",
    "        posterior = self.model.posterior(X)\n",
    "        return posterior.mean, posterior.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f1cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import KroneckerMultiTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from functools import wraps\n",
    "from contextlib import redirect_stdout\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "\n",
    "\n",
    "# --- Logging 配置 ---\n",
    "logger = logging.getLogger(\"BO_Monitor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    ch = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 修復後的 Monitor Decorator\n",
    "# ============================================================\n",
    "def monitor(runtime=True, memory=True, condition=False):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            if not getattr(self, \"debug\", False):\n",
    "                return func(self, *args, **kwargs)\n",
    "            \n",
    "            if not hasattr(self, 'performance_history'):\n",
    "                self.performance_history = []\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            process = psutil.Process(os.getpid())\n",
    "            \n",
    "            result = func(self, *args, **kwargs)\n",
    "            \n",
    "            elapsed = time.perf_counter() - start_time\n",
    "            cpu_mem = process.memory_info().rss / 1024**2\n",
    "            \n",
    "            entry = {\n",
    "                \"iteration\": getattr(self, \"current_iter\", \"N/A\"),\n",
    "                \"function\": func.__name__,\n",
    "                \"runtime_sec\": round(elapsed, 4),\n",
    "                \"cpu_memory_mb\": round(cpu_mem, 2),\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                entry[\"gpu_alloc_mb\"] = round(torch.cuda.memory_allocated() / 1024**2, 2)\n",
    "\n",
    "            # --- 修復後的條件數計算邏輯 ---\n",
    "            if condition and getattr(self, \"model\", None) is not None:\n",
    "                cond_list = []\n",
    "                # 判斷是 ModelList 還是單一模型 (KMTGP/STGP)\n",
    "                sub_models = self.model.models if hasattr(self.model, \"models\") else [self.model]\n",
    "                \n",
    "                for m in sub_models:\n",
    "                    try:\n",
    "                        with torch.no_grad():\n",
    "                            # 獲取訓練協方差矩陣\n",
    "                            # 注意：KMTGP 的矩陣可能非常大，這裡做 to_dense 會很吃記憶體\n",
    "                            K = m.covar_module(m.train_inputs[0]).to_dense()\n",
    "                            # 加上 jitter 提高穩定性\n",
    "                            K += torch.eye(K.size(-1), device=K.device, dtype=K.dtype) * 1e-6\n",
    "                            eigvals = torch.linalg.eigvalsh(K)\n",
    "                            cond = (eigvals.max() / eigvals.min()).item()\n",
    "                            cond_list.append(cond)\n",
    "                    except Exception as e:\n",
    "                        cond_list.append(float('nan'))\n",
    "                entry[\"condition_numbers\"] = cond_list\n",
    "\n",
    "            self.performance_history.append(entry)\n",
    "            logger.info(f\"Finished {func.__name__} - {entry}\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "class CorrelationBaselineGPEmulator:\n",
    "    \"\"\"\n",
    "    Correlation Baseline Multi-Objective GP Emulator\n",
    "    =================================================\n",
    "\n",
    "    This implementation uses KroneckerMultiTaskGP to jointly model\n",
    "    multiple objectives while learning correlations between tasks.\n",
    "\n",
    "    Mathematical Form:\n",
    "\n",
    "        Y = f(X) + ε\n",
    "        f ~ MultiTaskGP(m, K_x ⊗ K_t)\n",
    "\n",
    "    where:\n",
    "\n",
    "        K_x : covariance function over input space\n",
    "        K_t : task covariance matrix modeling inter-task correlation\n",
    "\n",
    "    Note:\n",
    "        KroneckerMultiTaskGP requires all tasks to share\n",
    "        the same training inputs (fully observed design).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        dtype   = torch.double,\n",
    "        debug   = False,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.model = None\n",
    "        self.mll = None\n",
    "        self.debug = debug\n",
    "        self.performance_history = []\n",
    "        self.current_iter = 0\n",
    "\n",
    "\n",
    "\n",
    "    @monitor(runtime=True, memory=True, condition=True)\n",
    "    def fit(self, train_x: torch.Tensor, train_obj: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Fit a Kronecker Multi-Task GP model.\n",
    "\n",
    "        Important:\n",
    "            KroneckerMultiTaskGP assumes that all tasks are observed\n",
    "            at the same set of training input locations.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert single-objective case (N,) to (N, 1)\n",
    "        if train_obj.ndim == 1:\n",
    "            train_obj = train_obj.unsqueeze(-1)\n",
    "\n",
    "        num_tasks = train_obj.shape[-1]\n",
    "\n",
    "        # Construct the Kronecker Multi-Task GP\n",
    "        # The model automatically learns the task covariance matrix\n",
    "        self.model = KroneckerMultiTaskGP(\n",
    "            train_X=train_x,\n",
    "            train_Y=train_obj,\n",
    "            outcome_transform=Standardize(m=num_tasks),\n",
    "        )\n",
    "\n",
    "        # Multi-task GP uses ExactMarginalLogLikelihood\n",
    "        self.mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "\n",
    "        # Train model while suppressing optimization output\n",
    "        with open(os.devnull, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                fit_gpytorch_mll(self.mll)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save_performance_to_json(self, folder_path, filename=\"performance_report.json\"):\n",
    "        \"\"\"\n",
    "        將監控紀錄儲存至指定資料夾路徑。\n",
    "        \"\"\"\n",
    "        # 1. 確保資料夾存在，若不存在則自動建立\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            logger.info(f\"Created directory: {folder_path}\")\n",
    "\n",
    "        # 2. 合併完整路徑\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # 3. 寫入 JSON\n",
    "        try:\n",
    "            with open(full_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.performance_history, f, indent=4, ensure_ascii=False)\n",
    "            logger.info(f\"Successfully saved performance metrics to: {full_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save JSON: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, X: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Perform prediction using the trained model.\n",
    "\n",
    "        Returns:\n",
    "            posterior.mean      : shape (n, num_tasks)\n",
    "            posterior.variance  : shape (n, num_tasks)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been fitted yet.\")\n",
    "        \n",
    "        X = torch.as_tensor(X, dtype=self.dtype, device=self.device)\n",
    "        \n",
    "        # Switch to evaluation mode\n",
    "        self.model.eval()\n",
    "        self.model.likelihood.eval()\n",
    "        \n",
    "        posterior = self.model.posterior(X)\n",
    "        \n",
    "        # mean shape: (n, num_tasks)\n",
    "        # variance shape: (n, num_tasks)\n",
    "        return posterior.mean, posterior.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04349648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torch\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from functools import wraps\n",
    "from contextlib import redirect_stdout\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.means import Mean\n",
    "from botorch.models import KroneckerMultiTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Optimized Mean Function: IDXSFastScheffeMean \n",
    "# ============================================================\n",
    "class IdxsFastScheffeMean(Mean):\n",
    "    \"\"\"\n",
    "    High-performance Scheffé polynomial mean function.\n",
    "\n",
    "    Mathematical form:\n",
    "\n",
    "        m(z) =\n",
    "            Σ β_i z_i\n",
    "          + Σ β_ij z_i z_j\n",
    "          + Σ β_ijk z_i z_j z_k\n",
    "          + Σ β_ijkl z_i z_j z_k z_l\n",
    "\n",
    "    depending on order.\n",
    "\n",
    "    Design goals:\n",
    "    - No torch.pow\n",
    "    - No mask matrix\n",
    "    - No large broadcast tensor\n",
    "    - No Python inner loops in forward\n",
    "    - Optimized for optimize_acqf gradient loops\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, order=2):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            Number of mixture components (dimension d)\n",
    "\n",
    "        order : int\n",
    "            Polynomial order (1 ~ 4 supported)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.order = order\n",
    "\n",
    "        num_params = 0\n",
    "        \n",
    "        # --------------------------------------------------\n",
    "        # 1st-order terms (linear effects)\n",
    "        # --------------------------------------------------\n",
    "        # z1, z2, ..., zd\n",
    "        self.register_buffer(\"idx1\", torch.arange(input_dim))\n",
    "        num_params += input_dim\n",
    "\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 2nd-order interaction terms\n",
    "        # --------------------------------------------------\n",
    "        # zi * zj for i < j\n",
    "        if order >= 2:\n",
    "            idx2_i, idx2_j = torch.triu_indices(input_dim, input_dim, offset=1)\n",
    "            self.register_buffer(\"idx2_i\", idx2_i)\n",
    "            self.register_buffer(\"idx2_j\", idx2_j)\n",
    "            num_params += len(idx2_i)\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 3rd-order interaction terms\n",
    "        # --------------------------------------------------\n",
    "        # zi * zj * zk\n",
    "        if order >= 3:\n",
    "            comb3 = torch.combinations(torch.arange(input_dim), r=3)\n",
    "            self.register_buffer(\"idx3\", comb3)\n",
    "            num_params += comb3.shape[0]\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # 4th-order interaction terms\n",
    "        # --------------------------------------------------\n",
    "        # zi * zj * zk * zl\n",
    "\n",
    "        if order >= 4:\n",
    "            comb4 = torch.combinations(torch.arange(input_dim), r=4)\n",
    "            self.register_buffer(\"idx4\", comb4)\n",
    "            num_params += comb4.shape[0]\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Trainable coefficients β\n",
    "        # --------------------------------------------------\n",
    "        # Total parameters = Σ C(d, k)\n",
    "\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(num_params))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute Scheffé mean.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Tensor\n",
    "            Shape (..., n, d)\n",
    "            where d = input_dim\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mean : Tensor\n",
    "            Shape (..., n)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        features = []\n",
    "\n",
    "        # -------------------------\n",
    "        # 1st order\n",
    "        # -------------------------\n",
    "        features.append(X)\n",
    "\n",
    "        # -------------------------\n",
    "        # 2nd order\n",
    "        # -------------------------\n",
    "        if self.order >= 2:\n",
    "            F2 = X[..., self.idx2_i] * X[..., self.idx2_j]\n",
    "            features.append(F2)\n",
    "\n",
    "        # -------------------------\n",
    "        # 3rd order\n",
    "        # -------------------------\n",
    "        if self.order >= 3:\n",
    "            i, j, k = self.idx3.unbind(dim=1)\n",
    "            F3 = X[..., i] * X[..., j] * X[..., k]\n",
    "            features.append(F3)\n",
    "\n",
    "        # -------------------------\n",
    "        # 4th order\n",
    "        # -------------------------\n",
    "        if self.order >= 4:\n",
    "            i, j, k, l = self.idx4.unbind(dim=1)\n",
    "            F4 = X[..., i] * X[..., j] * X[..., k] * X[..., l]\n",
    "            features.append(F4)\n",
    "\n",
    "        # -------------------------\n",
    "        # Concatenate all polynomial terms\n",
    "        # -------------------------\n",
    "        F = torch.cat(features, dim=-1)\n",
    "\n",
    "        # Linear combination with β\n",
    "        return torch.matmul(F, self.beta)\n",
    "    \n",
    "\n",
    "# ============================================================\n",
    "# Monitoring Utilities & Decorator\n",
    "# ============================================================\n",
    "logger = logging.getLogger(\"BO_Monitor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    ch = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Monitor Decorator\n",
    "# ============================================================\n",
    "def monitor(runtime=True, memory=True, condition=False):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            if not getattr(self, \"debug\", False):\n",
    "                return func(self, *args, **kwargs)\n",
    "            \n",
    "            if not hasattr(self, 'performance_history'):\n",
    "                self.performance_history = []\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            process = psutil.Process(os.getpid())\n",
    "            \n",
    "            result = func(self, *args, **kwargs)\n",
    "            \n",
    "            elapsed = time.perf_counter() - start_time\n",
    "            cpu_mem = process.memory_info().rss / 1024**2\n",
    "            \n",
    "            entry = {\n",
    "                \"iteration\": getattr(self, \"current_iter\", \"N/A\"),\n",
    "                \"function\": func.__name__,\n",
    "                \"runtime_sec\": round(elapsed, 4),\n",
    "                \"cpu_memory_mb\": round(cpu_mem, 2),\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                entry[\"gpu_alloc_mb\"] = round(torch.cuda.memory_allocated() / 1024**2, 2)\n",
    "\n",
    "            # --- 修復後的條件數計算邏輯 ---\n",
    "            if condition and getattr(self, \"model\", None) is not None:\n",
    "                cond_list = []\n",
    "                # 判斷是 ModelList 還是單一模型 (KMTGP/STGP)\n",
    "                sub_models = self.model.models if hasattr(self.model, \"models\") else [self.model]\n",
    "                \n",
    "                for m in sub_models:\n",
    "                    try:\n",
    "                        with torch.no_grad():\n",
    "                            # 獲取訓練協方差矩陣\n",
    "                            # 注意：KMTGP 的矩陣可能非常大，這裡做 to_dense 會很吃記憶體\n",
    "                            K = m.covar_module(m.train_inputs[0]).to_dense()\n",
    "                            # 加上 jitter 提高穩定性\n",
    "                            K += torch.eye(K.size(-1), device=K.device, dtype=K.dtype) * 1e-6\n",
    "                            eigvals = torch.linalg.eigvalsh(K)\n",
    "                            cond = (eigvals.max() / eigvals.min()).item()\n",
    "                            cond_list.append(cond)\n",
    "                    except Exception as e:\n",
    "                        cond_list.append(float('nan'))\n",
    "                entry[\"condition_numbers\"] = cond_list\n",
    "\n",
    "            self.performance_history.append(entry)\n",
    "            logger.info(f\"Finished {func.__name__} - {entry}\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CorrelationIdxsScheffeTrendGPEmulator:\n",
    "    \"\"\"\n",
    "    Correlated Multi-Objective Gaussian Process Emulator\n",
    "    ====================================================\n",
    "\n",
    "    This class builds a multi-objective GP surrogate model:\n",
    "\n",
    "        y_k(z) = m_k(z) + g_k(z)\n",
    "\n",
    "    where:\n",
    "        m_k(z) = Scheffé polynomial trend\n",
    "        g_k(z) ~ GP(0, K_θ)\n",
    "\n",
    "    The correlation between objectives is modeled via\n",
    "    KroneckerMultiTaskGP.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : torch.device\n",
    "        Device for computation (CPU or GPU).\n",
    "\n",
    "    dtype : torch.dtype\n",
    "        Floating point precision.\n",
    "\n",
    "    scheffe_order : int\n",
    "        Polynomial order of Scheffé mean.\n",
    "\n",
    "    debug : bool\n",
    "        Enable runtime/memory diagnostics.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        dtype         = torch.double,\n",
    "        scheffe_order = 2,\n",
    "        debug         = False,   # Debug switch\n",
    "\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.model = None\n",
    "        self.mll = None\n",
    "\n",
    "        self.scheffe_order = scheffe_order\n",
    "        self.debug = debug\n",
    "\n",
    "        self.performance_history = []\n",
    "        self.current_iter = 0\n",
    "        self.model = None\n",
    "\n",
    "\n",
    "    @monitor(runtime=True, memory=True, condition=False)\n",
    "    def fit(self, train_x: torch.Tensor, train_obj: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Fit the multi-task GP model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_x : torch.Tensor\n",
    "            Shape (N, d)\n",
    "\n",
    "        train_obj : torch.Tensor\n",
    "            Shape (N, k)\n",
    "            k = number of objectives\n",
    "        \"\"\"\n",
    "\n",
    "        # If single objective (N,), convert to (N, 1)\n",
    "        if train_obj.ndim == 1:\n",
    "            train_obj = train_obj.unsqueeze(-1)\n",
    "\n",
    "        input_dim = train_x.shape[-1]\n",
    "        num_objectives = train_obj.shape[-1]\n",
    "\n",
    "\n",
    "        # Define Scheffé polynomial mean\n",
    "        mean_module = IdxsFastScheffeMean(\n",
    "            input_dim=input_dim,\n",
    "            order=self.scheffe_order,\n",
    "        )  \n",
    "\n",
    "\n",
    "        # Construct correlated multi-task GP\n",
    "        self.model = KroneckerMultiTaskGP(\n",
    "            train_X=train_x,\n",
    "            train_Y=train_obj,\n",
    "            outcome_transform=Standardize(m=num_objectives),\n",
    "            mean_module = mean_module\n",
    "        )\n",
    "\n",
    "        # Exact marginal log likelihood\n",
    "        self.mll = ExactMarginalLogLikelihood(self.model.likelihood, self.model)\n",
    "\n",
    "        with open(os.devnull, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                fit_gpytorch_mll(self.mll)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def save_performance_to_json(self, folder_path, filename=\"performance_report.json\"):\n",
    "        \"\"\"\n",
    "        將監控紀錄儲存至指定資料夾路徑。\n",
    "        \"\"\"\n",
    "        # 1. 確保資料夾存在，若不存在則自動建立\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            logger.info(f\"Created directory: {folder_path}\")\n",
    "\n",
    "        # 2. 合併完整路徑\n",
    "        full_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # 3. 寫入 JSON\n",
    "        try:\n",
    "            with open(full_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.performance_history, f, indent=4, ensure_ascii=False)\n",
    "            logger.info(f\"Successfully saved performance metrics to: {full_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save JSON: {str(e)}\")\n",
    "\n",
    "            \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, X ):\n",
    "        \"\"\"\n",
    "        Posterior prediction.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : torch.Tensor or array-like\n",
    "            Shape (n, d)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mean : torch.Tensor\n",
    "            Posterior predictive mean, shape (n, k)\n",
    "\n",
    "        var : torch.Tensor\n",
    "            Posterior predictive variance, shape (n, k)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been fitted yet.\")\n",
    "        \n",
    "        X = torch.as_tensor(X, dtype=self.dtype, device=self.device)\n",
    "        posterior = self.model.posterior(X)\n",
    "        mean = posterior.mean    # (n, k)\n",
    "        var = posterior.variance # (n, k)\n",
    "\n",
    "        return mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf9204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97007f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92190112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e7138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "device =  cuda\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.acquisition.multi_objective.logei import (\n",
    "    qLogExpectedHypervolumeImprovement,\n",
    "    qLogNoisyExpectedHypervolumeImprovement\n",
    ")\n",
    "from botorch import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 設定設備與型別\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float64\n",
    "torch.set_default_dtype(dtype)\n",
    "print('==='*5)\n",
    "print('device = ',device)\n",
    "print('==='*5)\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    'AA001','AA002','AA004','AA005','AA006','AW001','AW003','AW004','AW005','AW014',\n",
    "    'AX010','AX015','AX019','AX020','AX029','AX032','AX137','CM1002','CM1007','CM1008',\n",
    "    'CP2002','FR001','FR002','FR006','FR007','FR008','FR015','FR058','GF001','GF006',\n",
    "    'GF013','GF014','GF016','GF020','MF001','MF005','MF006','MF007','PR002','PR007',\n",
    "    'PR009','PR016','PR020','PR022','PR024','SS004','SS010'\n",
    "    ]\n",
    "TARGET_COLS = [\"SPGR\", \"TE\"]\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Oracle loader (standalone, aligned with colleague)\n",
    "# =====================================================\n",
    "def load_oracle(beta_csv_path):\n",
    "    df = pd.read_csv(beta_csv_path)\n",
    "\n",
    "    if \"active\" in df.columns:\n",
    "        df = df[df[\"active\"].astype(bool)].copy()\n",
    "\n",
    "    # intercept\n",
    "    inter = df[df[\"type\"].str.lower() == \"intercept_correction\"]\n",
    "    intercept = torch.tensor(\n",
    "        inter.iloc[0][TARGET_COLS].astype(float).to_numpy(),\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "\n",
    "    feat_to_idx = {f: i for i, f in enumerate(FEATURE_COLS)}\n",
    "\n",
    "    # linear\n",
    "    lin_df = df[df[\"type\"].str.lower() == \"linear\"].copy()\n",
    "    lin_df[\"feat\"] = lin_df[\"feature\"].str.extract(r\"x\\[(.+?)\\]\")\n",
    "    lin_df[\"idx\"] = lin_df[\"feat\"].map(feat_to_idx)\n",
    "\n",
    "    beta_lin = torch.zeros((2, len(FEATURE_COLS)), device=device, dtype=dtype)\n",
    "    for _, r in lin_df.iterrows():\n",
    "        beta_lin[:, int(r[\"idx\"])] = torch.tensor(\n",
    "            r[TARGET_COLS].astype(float).to_numpy(),\n",
    "            device=device,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "    # interaction\n",
    "    int_df = df[df[\"type\"].str.lower() == \"interaction\"].copy()\n",
    "    mats = int_df[\"feature\"].str.extract(r\"x\\[(.+?)\\]\\*x\\[(.+?)\\]\")\n",
    "    int_df[\"i\"] = mats[0].map(feat_to_idx)\n",
    "    int_df[\"j\"] = mats[1].map(feat_to_idx)\n",
    "\n",
    "    pairs = torch.tensor(\n",
    "        int_df[[\"i\", \"j\"]].values.astype(int),\n",
    "        device=device,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    beta_inter = torch.tensor(\n",
    "        int_df[TARGET_COLS].astype(float).to_numpy(),\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    ).T\n",
    "\n",
    "    return {\n",
    "        \"intercept\": intercept,\n",
    "        \"beta_lin\": beta_lin,\n",
    "        \"pairs\": pairs,\n",
    "        \"beta_inter\": beta_inter,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def oracle_function(X, oracle):\n",
    "    intercept = oracle[\"intercept\"]\n",
    "    beta_lin = oracle[\"beta_lin\"]\n",
    "    pairs = oracle[\"pairs\"]\n",
    "    beta_inter = oracle[\"beta_inter\"]\n",
    "\n",
    "    lin = X @ beta_lin.T\n",
    "    cross = X[:, pairs[:, 0]] * X[:, pairs[:, 1]]\n",
    "    inter = cross @ beta_inter.T\n",
    "    return intercept.unsqueeze(0) + lin + inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aff837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:21,613 - INFO - Finished fit - {'iteration': 0, 'function': 'fit', 'runtime_sec': 1.5435, 'cpu_memory_mb': 968.36, 'timestamp': '2026-02-26 09:17:21', 'gpu_alloc_mb': 16.34, 'condition_numbers': [1550202.2893797294, 216063.2665307227]}\n",
      "2026-02-26 09:17:21,613 - INFO - Created directory: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\n",
      "2026-02-26 09:17:21,620 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  1.5536684999242425\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.1468301999848336\n",
      "optimize_acqf time =  2.077849799999967\n",
      "Append new data time =  0.0022368000354617834\n",
      "------------------------------\n",
      "Iter 00 | HV = 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:24,251 - INFO - Finished fit - {'iteration': 1, 'function': 'fit', 'runtime_sec': 0.3965, 'cpu_memory_mb': 1250.44, 'timestamp': '2026-02-26 09:17:24', 'gpu_alloc_mb': 17.04, 'condition_numbers': [1765742.4494488677, 226798.01829249453]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.40388659993186593\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.07702270010486245\n",
      "optimize_acqf time =  2.510609900113195\n",
      "Append new data time =  0.0022243999410420656\n",
      "------------------------------\n",
      "Iter 01 | HV = 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:27,329 - INFO - Finished fit - {'iteration': 2, 'function': 'fit', 'runtime_sec': 0.4759, 'cpu_memory_mb': 1277.93, 'timestamp': '2026-02-26 09:17:27', 'gpu_alloc_mb': 17.65, 'condition_numbers': [1971692.947713536, 268846.23097274656]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.4880367999430746\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09326200000941753\n",
      "optimize_acqf time =  1.9612712999805808\n",
      "Append new data time =  0.004444099962711334\n",
      "------------------------------\n",
      "Iter 02 | HV = 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:29,879 - INFO - Finished fit - {'iteration': 3, 'function': 'fit', 'runtime_sec': 0.4817, 'cpu_memory_mb': 1285.35, 'timestamp': '2026-02-26 09:17:29', 'gpu_alloc_mb': 18.23, 'condition_numbers': [2078620.5079629829, 281817.79863974074]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.4920977000147104\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.0928897000849247\n",
      "optimize_acqf time =  2.7404368000570685\n",
      "Append new data time =  0.005232099909335375\n",
      "------------------------------\n",
      "Iter 03 | HV = 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:33,271 - INFO - Finished fit - {'iteration': 4, 'function': 'fit', 'runtime_sec': 0.5391, 'cpu_memory_mb': 1286.97, 'timestamp': '2026-02-26 09:17:33', 'gpu_alloc_mb': 18.86, 'condition_numbers': [1997012.333505187, 286509.99700768647]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5520532999653369\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.08926669997163117\n",
      "optimize_acqf time =  3.2791034001857042\n",
      "Append new data time =  0.002574299927800894\n",
      "------------------------------\n",
      "Iter 04 | HV = 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:37,169 - INFO - Finished fit - {'iteration': 5, 'function': 'fit', 'runtime_sec': 0.5172, 'cpu_memory_mb': 1284.4, 'timestamp': '2026-02-26 09:17:37', 'gpu_alloc_mb': 19.48, 'condition_numbers': [1889733.1472501885, 290622.1385355932]}\n",
      "2026-02-26 09:17:37,178 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_5.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5291541998740286\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.08869549981318414\n",
      "optimize_acqf time =  3.122452100040391\n",
      "Append new data time =  0.0032170999329537153\n",
      "------------------------------\n",
      "Iter 05 | HV = 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:40,851 - INFO - Finished fit - {'iteration': 6, 'function': 'fit', 'runtime_sec': 0.45, 'cpu_memory_mb': 1286.38, 'timestamp': '2026-02-26 09:17:40', 'gpu_alloc_mb': 20.13, 'condition_numbers': [2097555.8314144793, 326890.6671097928]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.46338650002144277\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.0908730998635292\n",
      "optimize_acqf time =  4.85911069996655\n",
      "Append new data time =  0.003948200028389692\n",
      "------------------------------\n",
      "Iter 06 | HV = 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:46,306 - INFO - Finished fit - {'iteration': 7, 'function': 'fit', 'runtime_sec': 0.4862, 'cpu_memory_mb': 1287.44, 'timestamp': '2026-02-26 09:17:46', 'gpu_alloc_mb': 20.83, 'condition_numbers': [2115869.1358845904, 333878.7988564516]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5006440998986363\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09585529984906316\n",
      "optimize_acqf time =  1.78437320003286\n",
      "Append new data time =  0.004162200028076768\n",
      "------------------------------\n",
      "Iter 07 | HV = 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:48,714 - INFO - Finished fit - {'iteration': 8, 'function': 'fit', 'runtime_sec': 0.5052, 'cpu_memory_mb': 1287.8, 'timestamp': '2026-02-26 09:17:48', 'gpu_alloc_mb': 20.85, 'condition_numbers': [2206430.073436203, 394728.7931821894]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5179940999951214\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09135130001232028\n",
      "optimize_acqf time =  3.425385700073093\n",
      "Append new data time =  0.005737399915233254\n",
      "------------------------------\n",
      "Iter 08 | HV = 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:52,735 - INFO - Finished fit - {'iteration': 9, 'function': 'fit', 'runtime_sec': 0.4865, 'cpu_memory_mb': 1286.27, 'timestamp': '2026-02-26 09:17:52', 'gpu_alloc_mb': 21.69, 'condition_numbers': [2263766.116579966, 417189.7003601374]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.49827959993854165\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09101890004239976\n",
      "optimize_acqf time =  4.928849500138313\n",
      "Append new data time =  0.003979999804869294\n",
      "------------------------------\n",
      "Iter 09 | HV = 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:17:58,254 - INFO - Finished fit - {'iteration': 10, 'function': 'fit', 'runtime_sec': 0.4856, 'cpu_memory_mb': 1286.3, 'timestamp': '2026-02-26 09:17:58', 'gpu_alloc_mb': 21.6, 'condition_numbers': [2375662.9681418403, 403635.15054798184]}\n",
      "2026-02-26 09:17:58,264 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_10.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.49911849992349744\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09276230004616082\n",
      "optimize_acqf time =  5.04139419994317\n",
      "Append new data time =  0.00436159991659224\n",
      "------------------------------\n",
      "Iter 10 | HV = 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:03,941 - INFO - Finished fit - {'iteration': 11, 'function': 'fit', 'runtime_sec': 0.5245, 'cpu_memory_mb': 1286.86, 'timestamp': '2026-02-26 09:18:03', 'gpu_alloc_mb': 22.5, 'condition_numbers': [2424348.205934946, 393279.10253412434]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.540412399917841\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09474719990976155\n",
      "optimize_acqf time =  4.496718500042334\n",
      "Append new data time =  0.004996299976482987\n",
      "------------------------------\n",
      "Iter 11 | HV = 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:09,016 - INFO - Finished fit - {'iteration': 12, 'function': 'fit', 'runtime_sec': 0.4637, 'cpu_memory_mb': 1286.82, 'timestamp': '2026-02-26 09:18:09', 'gpu_alloc_mb': 17.25, 'condition_numbers': [1904669.8674337473, 416413.5962614226]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.4761691000312567\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09471269999630749\n",
      "optimize_acqf time =  5.280647400068119\n",
      "Append new data time =  0.003587799845263362\n",
      "------------------------------\n",
      "Iter 12 | HV = 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:14,854 - INFO - Finished fit - {'iteration': 13, 'function': 'fit', 'runtime_sec': 0.4461, 'cpu_memory_mb': 1289.0, 'timestamp': '2026-02-26 09:18:14', 'gpu_alloc_mb': 18.01, 'condition_numbers': [1944978.6292197956, 405268.92701360636]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.45900999987497926\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09215679997578263\n",
      "optimize_acqf time =  4.266474799951538\n",
      "Append new data time =  0.009009199915453792\n",
      "------------------------------\n",
      "Iter 13 | HV = 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:19,747 - INFO - Finished fit - {'iteration': 14, 'function': 'fit', 'runtime_sec': 0.5095, 'cpu_memory_mb': 1286.5, 'timestamp': '2026-02-26 09:18:19', 'gpu_alloc_mb': 18.93, 'condition_numbers': [2016319.4238254605, 417526.1600399777]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5240220001433045\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09369669994339347\n",
      "optimize_acqf time =  4.352448599878699\n",
      "Append new data time =  0.0028303000144660473\n",
      "------------------------------\n",
      "Iter 14 | HV = 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:24,710 - INFO - Finished fit - {'iteration': 15, 'function': 'fit', 'runtime_sec': 0.5031, 'cpu_memory_mb': 1286.74, 'timestamp': '2026-02-26 09:18:24', 'gpu_alloc_mb': 18.95, 'condition_numbers': [1855034.0540758967, 428054.89488578023]}\n",
      "2026-02-26 09:18:24,719 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_15.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.516865000128746\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09368629986420274\n",
      "optimize_acqf time =  3.1984840999357402\n",
      "Append new data time =  0.0029988999012857676\n",
      "------------------------------\n",
      "Iter 15 | HV = 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:28,590 - INFO - Finished fit - {'iteration': 16, 'function': 'fit', 'runtime_sec': 0.563, 'cpu_memory_mb': 1286.71, 'timestamp': '2026-02-26 09:18:28', 'gpu_alloc_mb': 19.72, 'condition_numbers': [1840086.9240213481, 464045.6624436911]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5752246999181807\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09008320001885295\n",
      "optimize_acqf time =  3.7272101999260485\n",
      "Append new data time =  0.0034397998824715614\n",
      "------------------------------\n",
      "Iter 16 | HV = 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:32,962 - INFO - Finished fit - {'iteration': 17, 'function': 'fit', 'runtime_sec': 0.5425, 'cpu_memory_mb': 1289.68, 'timestamp': '2026-02-26 09:18:32', 'gpu_alloc_mb': 20.46, 'condition_numbers': [1891985.4980575147, 459593.0001397644]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5537382999900728\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09555319999344647\n",
      "optimize_acqf time =  3.6688618999905884\n",
      "Append new data time =  0.0030851000919938087\n",
      "------------------------------\n",
      "Iter 17 | HV = 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:37,249 - INFO - Finished fit - {'iteration': 18, 'function': 'fit', 'runtime_sec': 0.5016, 'cpu_memory_mb': 1286.79, 'timestamp': '2026-02-26 09:18:37', 'gpu_alloc_mb': 21.25, 'condition_numbers': [27887786.594196662, 1405686.447757989]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5161397000774741\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09643529984168708\n",
      "optimize_acqf time =  3.71899909991771\n",
      "Append new data time =  0.007159799803048372\n",
      "------------------------------\n",
      "Iter 18 | HV = 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:41,592 - INFO - Finished fit - {'iteration': 19, 'function': 'fit', 'runtime_sec': 0.511, 'cpu_memory_mb': 1289.82, 'timestamp': '2026-02-26 09:18:41', 'gpu_alloc_mb': 22.06, 'condition_numbers': [29657674.062378198, 1940581.039651591]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5232745001558214\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09418960008770227\n",
      "optimize_acqf time =  4.019192300038412\n",
      "Append new data time =  0.0044386000372469425\n",
      "------------------------------\n",
      "Iter 19 | HV = 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:46,222 - INFO - Finished fit - {'iteration': 20, 'function': 'fit', 'runtime_sec': 0.5009, 'cpu_memory_mb': 1289.97, 'timestamp': '2026-02-26 09:18:46', 'gpu_alloc_mb': 22.89, 'condition_numbers': [419059966.4806875, 19758071.253134]}\n",
      "2026-02-26 09:18:46,232 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_20.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5146978998091072\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09754070010967553\n",
      "optimize_acqf time =  7.515596200013533\n",
      "Append new data time =  0.006235500099137425\n",
      "------------------------------\n",
      "Iter 20 | HV = 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:18:54,472 - INFO - Finished fit - {'iteration': 21, 'function': 'fit', 'runtime_sec': 0.6151, 'cpu_memory_mb': 1287.21, 'timestamp': '2026-02-26 09:18:54', 'gpu_alloc_mb': 23.73, 'condition_numbers': [5298273110.320557, 163086682.96198508]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.6233431999571621\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.07041879999451339\n",
      "optimize_acqf time =  5.016148899914697\n",
      "Append new data time =  0.004981100093573332\n",
      "------------------------------\n",
      "Iter 21 | HV = 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:00,117 - INFO - Finished fit - {'iteration': 22, 'function': 'fit', 'runtime_sec': 0.5274, 'cpu_memory_mb': 1290.14, 'timestamp': '2026-02-26 09:19:00', 'gpu_alloc_mb': 24.59, 'condition_numbers': [5491311414.120406, 136813141.650737]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5479298999998719\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09190020011737943\n",
      "optimize_acqf time =  5.175163300009444\n",
      "Append new data time =  0.005672400118783116\n",
      "------------------------------\n",
      "Iter 22 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:06,085 - INFO - Finished fit - {'iteration': 23, 'function': 'fit', 'runtime_sec': 0.6765, 'cpu_memory_mb': 1290.64, 'timestamp': '2026-02-26 09:19:06', 'gpu_alloc_mb': 25.48, 'condition_numbers': [5963785589.271504, 149439074.32958212]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.6940461997874081\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09278720011934638\n",
      "optimize_acqf time =  2.443908100016415\n",
      "Append new data time =  0.008297499967738986\n",
      "------------------------------\n",
      "Iter 23 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:09,317 - INFO - Finished fit - {'iteration': 24, 'function': 'fit', 'runtime_sec': 0.669, 'cpu_memory_mb': 1291.01, 'timestamp': '2026-02-26 09:19:09', 'gpu_alloc_mb': 26.39, 'condition_numbers': [144135626992.6962, 4711028640.584893]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.6868326999247074\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.08694020006805658\n",
      "optimize_acqf time =  2.1478982002008706\n",
      "Append new data time =  0.006840999936684966\n",
      "------------------------------\n",
      "Iter 24 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:12,168 - INFO - Finished fit - {'iteration': 25, 'function': 'fit', 'runtime_sec': 0.597, 'cpu_memory_mb': 1290.96, 'timestamp': '2026-02-26 09:19:12', 'gpu_alloc_mb': 27.34, 'condition_numbers': [16843358117179.69, 440097493535.9043]}\n",
      "2026-02-26 09:19:12,176 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_25.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.6126367000397295\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.0885489999782294\n",
      "optimize_acqf time =  2.839985999977216\n",
      "Append new data time =  0.0072650001384317875\n",
      "------------------------------\n",
      "Iter 25 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:15,700 - INFO - Finished fit - {'iteration': 26, 'function': 'fit', 'runtime_sec': 0.5776, 'cpu_memory_mb': 1291.13, 'timestamp': '2026-02-26 09:19:15', 'gpu_alloc_mb': 28.3, 'condition_numbers': [19698186742436.05, 505130586664.9099]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5937988001387566\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.08181230002082884\n",
      "optimize_acqf time =  5.277998399920762\n",
      "Append new data time =  0.006992199923843145\n",
      "------------------------------\n",
      "Iter 26 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:21,664 - INFO - Finished fit - {'iteration': 27, 'function': 'fit', 'runtime_sec': 0.5779, 'cpu_memory_mb': 1291.38, 'timestamp': '2026-02-26 09:19:21', 'gpu_alloc_mb': 29.29, 'condition_numbers': [75529761520143.11, 2154463129431.689]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5936292000114918\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.12652730010449886\n",
      "optimize_acqf time =  4.53218590002507\n",
      "Append new data time =  0.011487900046631694\n",
      "------------------------------\n",
      "Iter 27 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:27,090 - INFO - Finished fit - {'iteration': 28, 'function': 'fit', 'runtime_sec': 0.7373, 'cpu_memory_mb': 1291.7, 'timestamp': '2026-02-26 09:19:27', 'gpu_alloc_mb': 30.3, 'condition_numbers': [117195286989298.02, 3079774716875.684]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.7533942998852581\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.11681840009987354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  13.517321899998933\n",
      "Append new data time =  0.006384399952366948\n",
      "------------------------------\n",
      "Iter 28 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:41,319 - INFO - Finished fit - {'iteration': 29, 'function': 'fit', 'runtime_sec': 0.5793, 'cpu_memory_mb': 1305.66, 'timestamp': '2026-02-26 09:19:41', 'gpu_alloc_mb': 31.33, 'condition_numbers': [387080445427716.2, 76399285756476.62]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5921102999709547\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.08926720009185374\n",
      "optimize_acqf time =  5.567428499925882\n",
      "Append new data time =  0.010679499944671988\n",
      "------------------------------\n",
      "Iter 29 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:47,505 - INFO - Finished fit - {'iteration': 30, 'function': 'fit', 'runtime_sec': 0.4978, 'cpu_memory_mb': 1297.2, 'timestamp': '2026-02-26 09:19:47', 'gpu_alloc_mb': 32.38, 'condition_numbers': [819870792680079.6, 104481671958044.08]}\n",
      "2026-02-26 09:19:47,505 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_30.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5131020999979228\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.10130049986764789\n",
      "optimize_acqf time =  2.9249390000477433\n",
      "Append new data time =  0.012791600078344345\n",
      "------------------------------\n",
      "Iter 30 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:19:51,377 - INFO - Finished fit - {'iteration': 31, 'function': 'fit', 'runtime_sec': 0.8149, 'cpu_memory_mb': 1300.47, 'timestamp': '2026-02-26 09:19:51', 'gpu_alloc_mb': 33.47, 'condition_numbers': [1.7058518016758928e+16, 362190390874456.06]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.8279722998850048\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09381380002014339\n",
      "optimize_acqf time =  8.141352799953893\n",
      "Append new data time =  0.00708639994263649\n",
      "------------------------------\n",
      "Iter 31 | HV = 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:20:00,053 - INFO - Finished fit - {'iteration': 32, 'function': 'fit', 'runtime_sec': 0.423, 'cpu_memory_mb': 1299.93, 'timestamp': '2026-02-26 09:20:00', 'gpu_alloc_mb': 17.71, 'condition_numbers': [1.382273927901056e+16, 312285890477888.44]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.4313021001871675\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09002620005048811\n",
      "optimize_acqf time =  5.985519899986684\n",
      "Append new data time =  0.0077991001307964325\n",
      "------------------------------\n",
      "Iter 32 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:20:06,678 - INFO - Finished fit - {'iteration': 33, 'function': 'fit', 'runtime_sec': 0.5387, 'cpu_memory_mb': 1300.12, 'timestamp': '2026-02-26 09:20:06', 'gpu_alloc_mb': 18.82, 'condition_numbers': [1.7119116280815688e+16, 476889717805830.6]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5477011001203209\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09308260004036129\n",
      "optimize_acqf time =  8.842956600012258\n",
      "Append new data time =  0.015148899983614683\n",
      "------------------------------\n",
      "Iter 33 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:20:16,409 - INFO - Finished fit - {'iteration': 34, 'function': 'fit', 'runtime_sec': 0.7604, 'cpu_memory_mb': 1300.89, 'timestamp': '2026-02-26 09:20:16', 'gpu_alloc_mb': 20.18, 'condition_numbers': [1.7088381557148748e+16, 549230208867104.94]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.7722930999007076\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.11016469984315336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  12.548267000121996\n",
      "Append new data time =  0.011487300042062998\n",
      "------------------------------\n",
      "Iter 34 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:20:29,642 - INFO - Finished fit - {'iteration': 35, 'function': 'fit', 'runtime_sec': 0.5472, 'cpu_memory_mb': 1314.89, 'timestamp': '2026-02-26 09:20:29', 'gpu_alloc_mb': 21.36, 'condition_numbers': [1.9285320938156028e+16, 658698317182975.6]}\n",
      "2026-02-26 09:20:29,644 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_35.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5621489000041038\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.14805729989893734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  15.937390200095251\n",
      "Append new data time =  0.01882560015656054\n",
      "------------------------------\n",
      "Iter 35 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:20:46,328 - INFO - Finished fit - {'iteration': 36, 'function': 'fit', 'runtime_sec': 0.5613, 'cpu_memory_mb': 1316.16, 'timestamp': '2026-02-26 09:20:46', 'gpu_alloc_mb': 22.55, 'condition_numbers': [3.121025438620007e+17, 3.1744723292432532e+16]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.578684400068596\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.12936440017074347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  15.553027000045404\n",
      "Append new data time =  0.016985800117254257\n",
      "------------------------------\n",
      "Iter 36 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:02,695 - INFO - Finished fit - {'iteration': 37, 'function': 'fit', 'runtime_sec': 0.6464, 'cpu_memory_mb': 1316.65, 'timestamp': '2026-02-26 09:21:02', 'gpu_alloc_mb': 23.81, 'condition_numbers': [-1.640726530396258e+17, 7.1715142779078536e+16]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.664096700027585\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.11376580013893545\n",
      "optimize_acqf time =  7.301668899832293\n",
      "Append new data time =  0.0221261999104172\n",
      "------------------------------\n",
      "Iter 37 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:10,607 - INFO - Finished fit - {'iteration': 38, 'function': 'fit', 'runtime_sec': 0.456, 'cpu_memory_mb': 1306.75, 'timestamp': '2026-02-26 09:21:10', 'gpu_alloc_mb': 25.35, 'condition_numbers': [-2.886288240709244e+17, -1.0932669701694136e+16]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.47420920012518764\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09632709994912148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  14.303659399971366\n",
      "Append new data time =  0.019887599861249328\n",
      "------------------------------\n",
      "Iter 38 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:25,536 - INFO - Finished fit - {'iteration': 39, 'function': 'fit', 'runtime_sec': 0.4926, 'cpu_memory_mb': 1314.18, 'timestamp': '2026-02-26 09:21:25', 'gpu_alloc_mb': 26.66, 'condition_numbers': [-6205068298196533.0, -1631800947964264.0]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5086449000518769\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.10795380012132227\n",
      "optimize_acqf time =  2.9915130001027137\n",
      "Append new data time =  0.012091599870473146\n",
      "------------------------------\n",
      "Iter 39 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:29,048 - INFO - Finished fit - {'iteration': 40, 'function': 'fit', 'runtime_sec': 0.3849, 'cpu_memory_mb': 1304.32, 'timestamp': '2026-02-26 09:21:29', 'gpu_alloc_mb': 28.0, 'condition_numbers': [-4690000187086828.0, 9.408738805878915e+18]}\n",
      "2026-02-26 09:21:29,048 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_40.json\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.40126439998857677\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.10186349996365607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-07 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-06 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-07 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  9.167643800145015\n",
      "Append new data time =  0.017492499900981784\n",
      "------------------------------\n",
      "Iter 40 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:38,748 - INFO - Finished fit - {'iteration': 41, 'function': 'fit', 'runtime_sec': 0.3858, 'cpu_memory_mb': 1314.74, 'timestamp': '2026-02-26 09:21:38', 'gpu_alloc_mb': 29.35, 'condition_numbers': [-2.9724169857218576e+16, -4.1628588239435706e+17]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.40661679999902844\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.1215737999882549\n",
      "optimize_acqf time =  1.7424367999192327\n",
      "Append new data time =  0.013317300006747246\n",
      "------------------------------\n",
      "Iter 41 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:41,042 - INFO - Finished fit - {'iteration': 42, 'function': 'fit', 'runtime_sec': 0.4019, 'cpu_memory_mb': 1304.88, 'timestamp': '2026-02-26 09:21:41', 'gpu_alloc_mb': 30.75, 'condition_numbers': [-3287194340111664.0, -4.88264473874163e+17]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.42006790009327233\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09805279993452132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  5.600873299874365\n",
      "Append new data time =  0.020087100099772215\n",
      "------------------------------\n",
      "Iter 42 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:21:47,187 - INFO - Finished fit - {'iteration': 43, 'function': 'fit', 'runtime_sec': 0.4033, 'cpu_memory_mb': 1304.73, 'timestamp': '2026-02-26 09:21:47', 'gpu_alloc_mb': 32.13, 'condition_numbers': [-3.448676034535056e+17, 4.782130356436914e+17]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.4206905998289585\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09981289994902909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-07 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-06 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-05 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-04 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-07 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-06 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-05 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-04 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-03 to the diagonal'), BotorchWarning('Low-rank cholesky updates failed due NaNs or due to an ill-conditioned covariance matrix. Falling back to standard sampling.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  17.382104099960998\n",
      "Append new data time =  0.014113600132986903\n",
      "------------------------------\n",
      "Iter 43 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:22:05,053 - INFO - Finished fit - {'iteration': 44, 'function': 'fit', 'runtime_sec': 0.3567, 'cpu_memory_mb': 1314.91, 'timestamp': '2026-02-26 09:22:05', 'gpu_alloc_mb': 33.55, 'condition_numbers': [-2.47945831837284e+17, -3.5196635172228954e+17]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.37564999982714653\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.10458460007794201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  17.56327879987657\n",
      "Append new data time =  0.016730699921026826\n",
      "------------------------------\n",
      "Iter 44 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:22:23,280 - INFO - Finished fit - {'iteration': 45, 'function': 'fit', 'runtime_sec': 0.5166, 'cpu_memory_mb': 1315.01, 'timestamp': '2026-02-26 09:22:23', 'gpu_alloc_mb': 35.02, 'condition_numbers': [-9.295602775411821e+17, -2.192934205289292e+17]}\n",
      "2026-02-26 09:22:23,284 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\perf_iter_45.json\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.536779599962756\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.09495069994591177\n",
      "optimize_acqf time =  6.193931899964809\n",
      "Append new data time =  0.020441400120034814\n",
      "------------------------------\n",
      "Iter 45 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:22:30,073 - INFO - Finished fit - {'iteration': 46, 'function': 'fit', 'runtime_sec': 0.4676, 'cpu_memory_mb': 1304.91, 'timestamp': '2026-02-26 09:22:30', 'gpu_alloc_mb': 36.48, 'condition_numbers': [-3.500296842402618e+17, -1.2798232956421059e+18]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.47652880009263754\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.0834305000025779\n",
      "optimize_acqf time =  6.742163500050083\n",
      "Append new data time =  0.014825199963524938\n",
      "------------------------------\n",
      "Iter 46 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:22:37,394 - INFO - Finished fit - {'iteration': 47, 'function': 'fit', 'runtime_sec': 0.4645, 'cpu_memory_mb': 1306.46, 'timestamp': '2026-02-26 09:22:37', 'gpu_alloc_mb': 38.02, 'condition_numbers': [-4.108210182409858e+17, -2.182563877900651e+17]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.48039399995468557\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.1034948998130858\n",
      "optimize_acqf time =  6.63149239984341\n",
      "Append new data time =  0.017331300070509315\n",
      "------------------------------\n",
      "Iter 47 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:22:44,621 - INFO - Finished fit - {'iteration': 48, 'function': 'fit', 'runtime_sec': 0.4593, 'cpu_memory_mb': 1307.12, 'timestamp': '2026-02-26 09:22:44', 'gpu_alloc_mb': 39.55, 'condition_numbers': [-3.808650028718078e+17, -1.94009949861751e+17]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.4751167001668364\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.11642810003831983\n",
      "optimize_acqf time =  11.966160699957982\n",
      "Append new data time =  0.02590239979326725\n",
      "------------------------------\n",
      "Iter 48 | HV = 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:22:57,297 - INFO - Finished fit - {'iteration': 49, 'function': 'fit', 'runtime_sec': 0.55, 'cpu_memory_mb': 1307.16, 'timestamp': '2026-02-26 09:22:57', 'gpu_alloc_mb': 41.15, 'condition_numbers': [-3.783011208471727e+17, -3214406733503738.5]}\n",
      "d:\\Users\\TingYuLin\\Desktop\\py12\\venv\\Lib\\site-packages\\linear_operator\\utils\\cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "model fit time  =  0.5670469999313354\n",
      "qLogNoisyExpectedHypervolumeImprovement time =  0.13670890009962022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-26 09:23:03,205 - INFO - Successfully saved performance metrics to: D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\\final_performance_seed_39.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize_acqf time =  5.735966400010511\n",
      "Append new data time =  0.018379800021648407\n",
      "------------------------------\n",
      "Iter 49 | HV = 0.0073\n",
      "Saved → D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result/synthetic_data_sparse_seed_39.json\n"
     ]
    }
   ],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
    "\n",
    "\n",
    "seed  = '39'\n",
    "PATH  = \"D:/Users/TingYuLin/Desktop/py12/MOBO/synthetic_data_sparse_constraint_seed_39.csv\"\n",
    "# PATH2 = f\"./synthetic_data_sparse_seed_{seed}.csv\"\n",
    "N_ITER = 50\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "train_x = torch.tensor(df[FEATURE_COLS].values/100, device=device, dtype=dtype)\n",
    "train_obj = torch.tensor(df[TARGET_COLS].values, device=device, dtype=dtype)\n",
    "\n",
    "hv_history = []\n",
    "pareto_history = []\n",
    "all_X = [train_x.detach().cpu().numpy().tolist()]  # 存初始 X\n",
    "all_Y = [train_obj.detach().cpu().numpy().tolist()]  # 存初始 Y\n",
    "\n",
    "\n",
    "print(train_obj.shape)\n",
    "ref_point = torch.tensor([1.3654, 2.8482], dtype=dtype, device=device)\n",
    "\n",
    "\n",
    "\n",
    "SAVE_DIR = \"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result\"\n",
    "# SAVE_DIR = \"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_schyeffe_result\"\n",
    "# SAVE_DIR = \"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/coor_gp_result\"\n",
    "# SAVE_DIR = \"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/coor_base_schyeffe_result\"\n",
    "\n",
    "FILE_NAME = f\"final_performance_seed_{seed}.json\"\n",
    "\n",
    "\n",
    "BETA_CSV = \"D:/Users/TingYuLin/Desktop/py12/MOBO/beta1.csv\"\n",
    "oracle = load_oracle(BETA_CSV)\n",
    "\n",
    "\n",
    "gp_base = BaselineGPEmulator(kernel = 'rbf',debug=True)\n",
    "# gp_Scheffe = IdxsScheffeTrendGPEmulator(kernel = 'rbf', scheffe_order = 2, debug=True)\n",
    "# corr_gp_base = CorrelationBaselineGPEmulator(debug=True)\n",
    "# corr_Scheffe = CorrelationIdxsScheffeTrendGPEmulator(scheffe_order = 2, debug=True)\n",
    "\n",
    "\n",
    "input_dim = train_x.shape[-1]\n",
    "for it in range(N_ITER):\n",
    "\n",
    "\n",
    "    gp_base.current_iter = it\n",
    "    # gp_Scheffe.current_iter = it\n",
    "    # corr_gp_base.current_iter = it\n",
    "    # corr_Scheffe.current_iter = it\n",
    "\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    model = gp_base.fit(train_x,train_obj)\n",
    "    # model = gp_Scheffe.fit(train_x,train_obj)\n",
    "    # model = corr_gp_base.fit(train_x,train_obj)\n",
    "    # model = corr_Scheffe.fit(train_x,train_obj)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed = end_time - start_time\n",
    "\n",
    "    print('---'*10)\n",
    "    print('model fit time  = ', elapsed)\n",
    "\n",
    "    if it % 5 == 0:\n",
    "        gp_base.save_performance_to_json(SAVE_DIR, f\"perf_iter_{it}.json\")\n",
    "        # gp_Scheffe.save_performance_to_json(SAVE_DIR, f\"perf_iter_{it}.json\")\n",
    "        # corr_gp_base.save_performance_to_json(SAVE_DIR, f\"perf_iter_{it}.json\")\n",
    "        # corr_Scheffe.save_performance_to_json(SAVE_DIR, f\"perf_iter_{it}.json\")\n",
    "\n",
    "    start_time1 = time.perf_counter()\n",
    "\n",
    "    sampler = SobolQMCNormalSampler(sample_shape=torch.Size([128]))\n",
    "    \n",
    "    acq_func = qLogNoisyExpectedHypervolumeImprovement(\n",
    "            model=model,\n",
    "            ref_point=ref_point,\n",
    "            X_baseline=train_x,\n",
    "            sampler=sampler,\n",
    "            prune_baseline=True,\n",
    "        )\n",
    "\n",
    "\n",
    "    end_time1 = time.perf_counter()\n",
    "    elapsed1 = end_time1 - start_time1\n",
    "\n",
    "\n",
    "    print('qLogNoisyExpectedHypervolumeImprovement time = ', elapsed1)\n",
    "\n",
    "    bounds=torch.stack([\n",
    "        torch.zeros(len(FEATURE_COLS), device=device),\n",
    "        torch.ones(len(FEATURE_COLS), device=device),\n",
    "    ])\n",
    "\n",
    "    equality_constraints=[\n",
    "        (\n",
    "            torch.arange(len(FEATURE_COLS), device=device),\n",
    "            torch.ones(len(FEATURE_COLS), device=device),\n",
    "            1.0,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "    start_time2 = time.perf_counter()\n",
    "    new_x, _ = optimize_acqf(\n",
    "        acq_function = acq_func, \n",
    "        bounds = bounds, \n",
    "        q= 1, \n",
    "        num_restarts = 10, \n",
    "        raw_samples = 128, \n",
    "        equality_constraints = [\n",
    "            (\n",
    "                torch.arange(len(FEATURE_COLS), device=device),\n",
    "                torch.ones(len(FEATURE_COLS), device=device),\n",
    "                1.0,\n",
    "            )\n",
    "        ],\n",
    "        options={\n",
    "            \"batch_limit\": 5, \n",
    "            \"maxiter\": 200\n",
    "        }\n",
    "    )\n",
    "\n",
    "    end_time2 = time.perf_counter()\n",
    "    elapsed2 = end_time2 - start_time2\n",
    "\n",
    "    print('optimize_acqf time = ', elapsed2)\n",
    "\n",
    "    # pre_mean,pre_var = corr_Scheffe.predict(new_x)\n",
    "\n",
    "    # print('--'*50)\n",
    "    # print('pre_mean = ',pre_mean)\n",
    "    # print('pre_var = ',pre_var)\n",
    "    # print('--'*50)\n",
    "\n",
    "    start_time3 = time.perf_counter()\n",
    "    new_y = oracle_function(new_x, oracle)  # shape (1, 2)\n",
    "\n",
    "    # ============================\n",
    "    # Append new data\n",
    "    # ============================\n",
    "    train_x = torch.cat([train_x, new_x], dim=0)\n",
    "    train_obj = torch.cat([train_obj, new_y], dim=0)\n",
    "\n",
    "        # 存 X, Y\n",
    "    all_X.append(new_x.detach().cpu().numpy().tolist())\n",
    "    all_Y.append(new_y.detach().cpu().numpy().tolist())\n",
    "\n",
    "        # ============================\n",
    "    # Compute HV\n",
    "    # ============================\n",
    "    nd_mask = is_non_dominated(train_obj)\n",
    "    pareto = train_obj[nd_mask]\n",
    "\n",
    "    hv = Hypervolume(ref_point)\n",
    "    hv_val = hv.compute(pareto)\n",
    "\n",
    "    hv_history.append(hv_val)\n",
    "    pareto_history.append(pareto.detach().cpu().tolist())\n",
    "\n",
    "\n",
    "    end_time3 = time.perf_counter()\n",
    "    elapsed3 = end_time3 - start_time3\n",
    "    print('Append new data time = ', elapsed3)\n",
    "    print('---'*10)\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Iter {it:02d} | HV = {hv_val:.4f}\")\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# Save JSON per seed\n",
    "# =================================================\n",
    "out = {\n",
    "    \"seed\": seed,\n",
    "    \"hv_history\": hv_history,\n",
    "    \"pareto_history\": pareto_history,\n",
    "    \"all_X\": all_X,\n",
    "    \"all_Y\": all_Y,\n",
    "    \"n_evals\": train_x.shape[0],\n",
    "}\n",
    "\n",
    "\n",
    "with open(f\"{SAVE_DIR}/synthetic_data_sparse_seed_{seed}.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(f\"Saved → {SAVE_DIR}/synthetic_data_sparse_seed_{seed}.json\")\n",
    "\n",
    "# 最終存檔\n",
    "gp_base.save_performance_to_json(SAVE_DIR, FILE_NAME)\n",
    "# gp_Scheffe.save_performance_to_json(SAVE_DIR, FILE_NAME)\n",
    "# corr_gp_base.save_performance_to_json(SAVE_DIR, FILE_NAME)\n",
    "# corr_Scheffe.save_performance_to_json(SAVE_DIR, FILE_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc93a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56403360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cd0587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_averages(file_path):\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "#     if not data:\n",
    "#         return \"JSON 文件中沒有數據。\"\n",
    "    \n",
    "#     hv_history = data.get('hv_history')\n",
    "\n",
    "#     return hv_history\n",
    "\n",
    "\n",
    "# def tree_averages(file_path):\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "#     if not data:\n",
    "#         return \"JSON 文件中沒有數據。\"\n",
    "    \n",
    "#     return data\n",
    "\n",
    "\n",
    "\n",
    "# base_gp_hv_history = plot_averages(\"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_gp_result/synthetic_data_sparse_seed_39.json\")\n",
    "# Scheffé_gp_hv_history = plot_averages(\"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_schyeffe_result/synthetic_data_sparse_seed_39.json\")\n",
    "# rf_history = tree_averages(\"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/tree_result/hv_history.json\")\n",
    "# gb_history = tree_averages(\"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/tree_result/hv_history.json\")\n",
    "\n",
    "\n",
    "# # 3. 繪圖\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(base_gp_hv_history, marker='o', linestyle='-', color='#1f77b4', markersize=4, label='without Scheffé HV')\n",
    "# plt.plot(Scheffé_gp_hv_history, marker='o', linestyle='-', color=\"#49b41f\", markersize=4, label='with Scheffé HV')\n",
    "# plt.plot(rf_history, marker='o', linestyle='-', color=\"#c51515\", markersize=4, label='Random forest HV')\n",
    "# plt.plot(gb_history, marker='o', linestyle='-', color=\"#000000\", markersize=4, label=' Gradient Boosting HV')\n",
    "\n",
    "\n",
    "# # # 計算累積最大值 (Running Maximum) 以顯示收斂狀況\n",
    "# # running_max = [max(hv_history[:i+1]) for i in range(len(hv_history))]\n",
    "# # plt.step(range(len(running_max)), running_max, where='post', color='red', alpha=0.6, label='Best HV')\n",
    "\n",
    "# # 圖表格式設定\n",
    "# plt.title('Hypervolume (HV) Convergence - Multi-Objective BO', fontsize=14)\n",
    "# plt.xlabel('Iteration (Batch)', fontsize=12)\n",
    "# plt.ylabel('Hypervolume Indicator', fontsize=12)\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb70a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # 假設您的檔案名稱為 performance_report.json\n",
    "# def calculate_performance_averages(file_path):\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     if not data:\n",
    "#         return \"JSON 文件中沒有數據。\"\n",
    "\n",
    "#     n = len(data)\n",
    "    \n",
    "#     # 提取各項數值\n",
    "#     runtimes = [entry['runtime_sec'] for entry in data]\n",
    "#     cpu_mems = [entry['cpu_memory_mb'] for entry in data]\n",
    "#     gpu_mems = [entry.get('gpu_alloc_mb', 0) for entry in data] # 使用 get 以防某些紀錄沒用到 GPU\n",
    "\n",
    "#     # 計算平均\n",
    "#     avg_runtime = sum(runtimes) / n\n",
    "#     avg_cpu = sum(cpu_mems) / n\n",
    "#     avg_gpu = sum(gpu_mems) / n\n",
    "\n",
    "#     print(f\"--- Scheffe mean 統計報告 (共 {n} 筆紀錄) ---\")\n",
    "#     print(f\"平均執行時間: {avg_runtime:.4f} sec\")\n",
    "#     print(f\"平均 CPU 使用量: {avg_cpu:.2f} MB\")\n",
    "#     print(f\"平均 GPU 佔用量: {avg_gpu:.2f} MB\")\n",
    "\n",
    "# # 執行範例\n",
    "# calculate_performance_averages(\"D:/Users/TingYuLin/Desktop/py12/MOBO/Scheffe_gp/base_schyeffe_result/final_performance_seed_39.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b47088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
